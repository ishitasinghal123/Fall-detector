# ğŸ¤– Fall Detection using YOLOv8 Pose + SVM (Google Colab Project)

This repository presents a human **fall detection system** built using **YOLOv8 pose estimation** and a **Support Vector Machine (SVM)** classifier. The model is trained and tested using **Google Colab**, with pose keypoints extracted from a labeled image dataset of humans in fall and non-fall scenarios.

---

## ğŸ“Œ Project Overview

- ğŸ§ Extracts human keypoints from images using **YOLOv8-pose**
- ğŸ§  Trains an **SVM classifier** on normalized keypoints to detect:
  - `Fall` (label: `0`)
  - `Not Fall` (label: `1`)
- ğŸ–¼ï¸ Predicts on new images/videos
- ğŸ“Š Visualizes the output and saves processed results

---

## ğŸ“ Repository Structure

```text
fall-detection-colab/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ fall_detection_colab.ipynb       â† Colab notebook (full pipeline)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ fall_detector_classifier.pkl      â† Trained SVM classifier
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ sample_input_1.mp4                â† Input test video
â”‚   â”œâ”€â”€ output_1.mp4                      â† Video with fall prediction overlays
â”‚   â”œâ”€â”€ sample_input_2.mp4                â† Input test video
â”‚   â””â”€â”€ output_2.mp4                      â† Video with fall prediction overlays
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ README.md                         â† Instructions to download training dataset
â””â”€â”€ README.md                             â† This file
```

### ğŸ·ï¸ Labeling Convention

- Images with `fall` in their filenames are treated as class `0`
- Images with `notfall` in their filenames are treated as class `1`

Keypoint extraction and labeling logic is implemented inside the notebook.

ğŸ‘‰ See [`dataset/README.md`](dataset/README.md) for details of dataset used for training the classifier.

---

## ğŸ” How It Works

### ğŸ”¹ 1. Keypoint Extraction

- The YOLOv8 pose model (`yolov8n-pose.pt`) is used to extract 17 body keypoints (x, y) for each person in the image.

### ğŸ”¹ 2. Feature Normalization

- Extracted keypoints are normalized to account for person size and position.

### ğŸ”¹ 3. Classification

- A **Support Vector Machine (SVM)** is trained using the normalized keypoints to classify each pose as a `Fall` or `Not Fall`.

### ğŸ”¹ 4. Inference

- Predictions are run on test images/videos using the trained classifier.
- Fall and Not Fall cases are highlighted visually.

---

## ğŸ“¸ Sample Results

### ğŸ–¼ï¸ Image Output  
Shown in the colab notebook

### ğŸ¥ Video Output  
ğŸ§ Fall detected in video frame-by-frame  
ğŸ“ [`output_1.mp4`](samples/output_1.mp4)

### ğŸ¥ Video Output  
ğŸ§ Fall detected in video frame-by-frame  
ğŸ“· [`output_2.jpg`](samples/output_2.jpg)
